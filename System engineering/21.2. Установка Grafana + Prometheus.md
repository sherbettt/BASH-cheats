Учитывая предыдущий шаг, когда у нас уже имеется подготовленная конфигурация `Grafana + Loki + LogCLI + Promtail`, требуется изменить конфиг на `Grafana + Prometheus`.

Ссылки с подсказками:
1. [Официальная документация Grafana для Prometheus](https://grafana.com/docs/grafana/latest/datasources/prometheus/)
2. [Руководство по установке Prometheus на Linux](https://www.dmosk.ru/instruktions.php?object=prometheus-linux)
3. [Создание графиков в Grafana на основе данных из Prometheus](https://www.dmosk.ru/miniinstruktions.php?mini=grafana-prometheus)
4. [Настройка Prometheus и Grafana](https://redos.red-soft.ru/base/redos-7_3/7_3-administation/7_3-monitoring/7_3-prometheus-grafana/)
5. [Node Exporter Full](https://grafana.com/grafana/dashboards/1860-node-exporter-full/)



# Установка и настройка Prometheus в существующую систему Grafana + Loki

## Текущая система (работает, не трогать):
- ✅ **Grafana** (порт 3000) - визуализация
- ✅ **Loki** (порт 3100) - логирование (оставить)
- ✅ **Promtail** - сбор логов (оставить)
- ✅ **LogCLI** - CLI для запросов к Loki

## Цель:
Добавить **Prometheus** для сбора метрик, сохранив существующую систему логирования.
<br/>

## Интерфейсы
```bash
root@runelfrontdev /etc/prometheus
11:00:35 # ipa
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp3s0           UP             192.168.87.179/24 fe80::365a:60ff:fee5:393b/64 
zt7nnkx5rb       UNKNOWN        192.168.195.238/24 fe80::b8cd:d3ff:fe36:5b99/64 

root@starodubtcevs:~# ipa
lo               UNKNOWN        127.0.0.1/8 ::1/128 
ens3             UP             91.207.75.89/32 fe80::5054:ff:fe26:e918/64 
zt7nnkx5rb       UNKNOWN        192.168.195.122/24 fe80::b817:30ff:fe36:5c32/64 
```


## Шаг 1: Установка Prometheus на runelfrontdev

### Установите пакеты:
```bash
sudo apt update
sudo apt install -y prometheus prometheus-alertmanager prometheus-bind-exporter prometheus-nginx-exporter
```

### Проверьте установку:
```bash
prometheus --version
prometheus-node-exporter --version

# Создайте пользователя (если не создан)
sudo useradd --no-create-home --shell /bin/false prometheus 2>/dev/null || true
```
<br/>



## Шаг 2: Установка Node-exporter на все серверы

### На runelfrontdev (локальный):
```bash
sudo apt install -y prometheus-node-exporter prometheus-node-exporter-collectors
sudo systemctl enable --now prometheus-node-exporter
```

### Проверка на runelfrontdev:
```bash
prometheus-node-exporter --version
systemctl status prometheus prometheus-node-exporter --no-pager
sudo ss -tulpn | grep -E ':9090|:9100'
```

### На starodubtcevs (удалённый):
```bash
# Подключитесь к удалённому серверу
ssh root@starodubtcevs.hlab.kz "
sudo apt update
sudo apt install -y prometheus-node-exporter
sudo systemctl enable --now prometheus-node-exporter

# Проверка
prometheus-node-exporter --version
systemctl status prometheus-node-exporter --no-pager
sudo ss -tulpn | grep -E ':9090|:9100'
"
```
<br/>


## Шаг 3: Настройка конфигурации Prometheus

### Создайте backup текущего конфига:
```bash
sudo cp /etc/prometheus/prometheus.yml /etc/prometheus/prometheus.yml.backup
```

### Установите новую конфигурацию:
**`scrape_timeout`** должен быть строго меньше **`scrape_interval`**


<details>
<summary>❗ prometheus.yml - общий вид ❗</summary>

```yaml
# /etc/prometheus/prometheus.yml
# Конфигурационный файл Prometheus для мониторинга инфраструктуры

# ================= ГЛОБАЛЬНЫЕ НАСТРОЙКИ =================
global:
  # Интервал сбора метрик со всех целевых серверов
  # Каждые 15 секунд Prometheus будет опрашивать все targets
  scrape_interval: 15s
  
  # Интервал пересчёта правил для алертов и записей
  # Каждые 15 секунд проверяются alerting и recording rules
  evaluation_interval: 15s
  
  # Опциональные настройки (раскомментировать при необходимости):
  # external_labels:                   # Метки для всех time series
  #   cluster: 'prod'                  # Идентификатор кластера
  #   region: 'eu-west'                # Регион размещения

# ================= НАСТРОЙКИ ALERTMANAGER =================
# Конфигурация для отправки алертов в Alertmanager
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # Разкомментируйте и настройте при установке Alertmanager:
          # - localhost:9093          # Alertmanager по умолчанию слушает порт 9093
          
# ================= ФАЙЛЫ С ПРАВИЛАМИ =================
# Подключаемые файлы с правилами для алертов и записи метрик
rule_files:
  # Примеры файлов с правилами (создайте при необходимости):
  # - "alerts/node_rules.yml"        # Правила для node-exporter
  # - "alerts/prometheus_rules.yml"  # Правила для самого Prometheus
  # - "recording_rules.yml"          # Правила для предрасчёта метрик

# ================= КОНФИГУРАЦИИ СБОРА МЕТРИК =================
# Основной раздел - определяет какие сервисы и как мониторить

scrape_configs:
  # ================= 1. САМ PROMETHEUS =================
  # Мониторинг самого Prometheus (самомониторинг)
  - job_name: 'prometheus'
    # Статическая конфигурация целей
    static_configs:
      - targets: ['localhost:9090']  # Prometheus слушает на порту 9090
    # Дополнительные метки для этой группы целей
    labels:
      component: 'monitoring'        # Тип компонента
      service: 'prometheus'          # Имя сервиса
      env: 'production'              # Окружение

  # ================= 2. ЛОКАЛЬНЫЙ NODE-EXPORTER =================
  # Сбор системных метрик с локального сервера (runelfrontdev)
  - job_name: 'node-exporter-runelfrontdev'
    static_configs:
      - targets: ['localhost:9100']  # Node-exporter слушает на порту 9100
    labels:
      host: 'runelfrontdev'          # Имя хоста
      location: 'local'              # Локация (локальный сервер)
      component: 'infrastructure'    # Тип компонента
      service: 'node-exporter'       # Имя сервиса
      env: 'production'              # Окружение
    # Опциональные настройки:
    # scrape_timeout: 10s            # Таймаут сбора метрик (по умолчанию 10s)
    # scrape_interval: 15s           # Можно переопределить глобальный interval

  # ================= 3. УДАЛЁННЫЙ NODE-EXPORTER =================
  # Сбор системных метрик с удалённого сервера (starodubtcevs)
  - job_name: 'node-exporter-starodubtcevs'
    static_configs:
      # Используем ZeroTier IP для подключения к удалённому серверу
      - targets: ['192.168.195.122:9100']
    labels:
      host: 'starodubtcevs'          # Имя удалённого хоста
      location: 'remote'             # Локация (удалённый сервер)
      component: 'infrastructure'    # Тип компонента
      service: 'node-exporter'       # Имя сервиса
      env: 'production'              # Окружение
    # Увеличенный таймаут для удалённых подключений
    scrape_timeout: 30s
    # Дополнительные настройки для проблемных сетей:
    # Для медленных соединений можно увеличить:
    # scrape_interval: 30s            # Увеличение интервала опроса
    
    # Если нужна работа через прокси:
    # proxy_url: http://proxy.example.com:8080
    
    # Настройки TLS (если используется HTTPS):
    # tls_config:
    #   insecure_skip_verify: true   # Пропустить проверку сертификата (небезопасно!)
    #   ca_file: /path/to/ca.crt     # Путь к CA сертификату

  # ================= 4. МЕТРИКИ LOKI =================
  # Сбор внутренних метрик Loki (логирование)
  - job_name: 'loki-metrics'
    static_configs:
      - targets: ['localhost:3100']  # Loki слушает на порту 3100
    # Loki предоставляет метрики по пути /metrics
    metrics_path: '/metrics'
    labels:
      component: 'logging'           # Тип компонента (система логирования)
      service: 'loki'                # Имя сервиса
      env: 'production'              # Окружение
    # Увеличен интервал сбора, т.к. метрики логирования меняются медленнее
    scrape_interval: 30s

  # ================= 5. МЕТРИКИ PROMTAIL =================
  # Сбор метрик сборщика логов Promtail
  - job_name: 'promtail-metrics'
    static_configs:
      - targets: ['localhost:9080']  # Promtail слушает на порту 9080
    metrics_path: '/metrics'
    labels:
      component: 'logging'           # Тип компонента
      service: 'promtail'            # Имя сервиса
      env: 'production'              # Окружение
    scrape_interval: 30s

  # ================= 6. МЕТРИКИ GRAFANA =================
  # Сбор внутренних метрик Grafana
  - job_name: 'grafana-metrics'
    static_configs:
      - targets: ['localhost:3000']  # Grafana слушает на порту 3000
    metrics_path: '/metrics'
    scheme: 'http'                   # Протокол (http/https)
    labels:
      component: 'monitoring'        # Тип компонента
      service: 'grafana'             # Имя сервиса
      env: 'production'              # Окружение
    scrape_interval: 30s

  # ================= 7. BLACKBOX EXPORTER (ОПЦИОНАЛЬНО) =================
  # Для мониторинга доступности сервисов (HTTP/HTTPS/TCP/ICMP)
  # Установите blackbox_exporter: https://github.com/prometheus/blackbox_exporter
  # - job_name: 'blackbox-http'
  #   metrics_path: /probe
  #   params:
  #     module: [http_2xx]           # Модуль проверки HTTP 200 OK
  #   static_configs:
  #     - targets:
  #       - http://localhost:3000    # Проверка доступности Grafana
  #       - http://localhost:9090    # Проверка доступности Prometheus
  #       - http://localhost:3100    # Проверка доступности Loki
  #   relabel_configs:
  #     - source_labels: [__address__]
  #       target_label: __param_target
  #     - source_labels: [__param_target]
  #       target_label: instance
  #     - target_label: __address__
  #       replacement: localhost:9115  # Адрес blackbox_exporter

  # ================= 8. CADVISOR (ОПЦИОНАЛЬНО) =================
  # Для мониторинга контейнеров Docker
  # - job_name: 'cadvisor'
  #   static_configs:
  #     - targets: ['localhost:8080']  # cAdvisor порт по умолчанию
  #   labels:
  #     component: 'containers'
  #     service: 'cadvisor'

  # ================= 9. POSTGRES EXPORTER (ОПЦИОНАЛЬНО) =================
  # Для мониторинга баз данных PostgreSQL
  # - job_name: 'postgres-exporter'
  #   static_configs:
  #     - targets: ['localhost:9187']  # PostgreSQL exporter порт
  #   labels:
  #     component: 'database'
  #     service: 'postgres'

  # ================= 10. NGINX EXPORTER (ОПЦИОНАЛЬНО) =================
  # Для мониторинга Nginx
  # - job_name: 'nginx-exporter'
  #   static_configs:
  #     - targets: ['localhost:9113']  # Nginx exporter порт
  #   labels:
  #     component: 'web-server'
  #     service: 'nginx'

# ================= ПРИМЕЧАНИЯ ПО БЕЗОПАСНОСТИ =================
# 1. Ограничьте доступ к портам:
#    - 9090 (Prometheus) - только для внутреннего использования
#    - 9100 (Node-exporter) - только для Prometheus
#
# 2. Рассмотрите использование:
#    - Basic Auth: https://prometheus.io/docs/guides/basic-auth/
#    - TLS: https://prometheus.io/docs/prometheus/latest/configuration/https/
#    - Reverse Proxy (nginx/apache) с аутентификацией
#
# 3. Для продакшена рекомендуется:
#    - Вынести конфигурацию в отдельные файлы
#    - Использовать service discovery вместо static_configs
#    - Настроить Alertmanager для уведомлений
```
</details>

=-=-=-=-=-=-=-=
<details>
<summary>❗ prometheus.yml ❗</summary>

```yaml
# /etc/prometheus/prometheus.yml
# Конфигурация для мониторинга двух серверов через ZeroTier

global:
  scrape_interval: 30s      # Каждые 30 секунд собираем метрики
  evaluation_interval: 30s  # Каждые 30 секунд проверяем правила

# Настройки алертов (пока отключены)
alerting:
  alertmanagers:
    - static_configs:
        - targets: []
          # - alertmanager:9093  # Раскомментировать при установке Alertmanager

# Файлы с правилами (пока пусто)
rule_files:
  # - "alert_rules.yml"

# Конфигурации сбора метрик
scrape_configs:
  # =============== 1. САМ PROMETHEUS ===============
  # Мониторинг самого Prometheus
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
        labels:
          host: 'runelfrontdev'
          service: 'prometheus'
          component: 'monitoring'
          env: 'production'

  # =============== 2. ЛОКАЛЬНЫЙ СЕРВЕР (runelfrontdev) ===============
  # Node-exporter на локальном сервере
  - job_name: 'node-local'
    static_configs:
      - targets: ['localhost:9100']
        labels:
          host: 'runelfrontdev'
          service: 'node-exporter'
          component: 'infrastructure'
          location: 'local'
          env: 'production'

  # =============== 3. УДАЛЁННЫЙ СЕРВЕР (starodubtcevs) ===============
  # Node-exporter на удалённом сервере через ZeroTier
  - job_name: 'node-remote'
    static_configs:
      - targets: ['192.168.195.122:9100']
        labels:
          host: 'starodubtcevs'
          service: 'node-exporter'
          component: 'infrastructure'
          location: 'remote'
          env: 'production'
    scrape_timeout: 25s  # Увеличенный таймаут для удалённого сервера

  # =============== 4. LOKI (лог-система) ===============
  # Метрики системы логирования Loki
  - job_name: 'loki'
    static_configs:
      - targets: ['localhost:3100']
        labels:
          service: 'loki'
          component: 'logging'
    metrics_path: '/metrics'  # Loki предоставляет метрики по этому пути
    scrape_interval: 30s      # Метрики логирования меняются реже

  # =============== 5. PROMTAIL ===============
  # Метрики сборщика логов Promtail
  - job_name: 'promtail'
    static_configs:
      - targets: ['localhost:9080']
        labels:
          service: 'promtail'
          component: 'logging'
    metrics_path: '/metrics'
    scrape_interval: 30s

  # =============== 6. GRAFANA ===============
  # Метрики Grafana (опционально)
  - job_name: 'grafana'
    static_configs:
      - targets: ['localhost:3000']
        labels:
          service: 'grafana'
          component: 'monitoring'
    metrics_path: '/metrics'
    scrape_interval: 30s

# =============== 7. TEMPO ===============
# Метрики распределенной системы трассировки Tempo
- job_name: 'tempo'
  static_configs:
    - targets: ['localhost:3200']
      labels:
        service: 'tempo'
        component: 'tracing'
        instance: 'runelfrontdev'
        env: 'production'
  metrics_path: '/metrics'
  scrape_interval: 30s
  scrape_timeout: 15s
  
  # Дополнительные метки (опционально)
  # relabel_configs:
  #   - source_labels: [__address__]
  #     target_label: __param_target
  #   - source_labels: [__param_target]
  #     target_label: instance
```
</details>

=-=-=-=-=-=-=-=
<details>
<summary>❗ prometheus.yml - для трёх машин ❗</summary>

```yaml
# /etc/prometheus/prometheus.yml
# Конфигурация для мониторинга серверов через WireGuard

global:
  scrape_interval: 30s      # Каждые 30 секунд собираем метрики
  evaluation_interval: 30s  # Каждые 30 секунд проверяем правила

# Настройки алертов (пока отключены)
alerting:
  alertmanagers:
    - static_configs:
        - targets: []
          # - alertmanager:9093  # Раскомментировать при установке Alertmanager

# Файлы с правилами (пока пусто)
rule_files:
  # - "alert_rules.yml"

# Конфигурации сбора метрик
scrape_configs:
  # =============== 1. САМ PROMETHEUS ===============
  # Мониторинг самого Prometheus
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
        labels:
          host: 'runelfrontdev'
          service: 'prometheus'
          component: 'monitoring'
          env: 'production'

  # =============== 2. ЛОКАЛЬНЫЙ СЕРВЕР (runelfrontdev) ===============
  # Node-exporter на локальном сервере
  - job_name: 'grafana-local'
    static_configs:
      - targets: ['localhost:9100']
        labels:
          host: 'runelfrontdev'
          service: 'node-exporter'
          component: 'infrastructure'
          location: 'local'
          env: 'production'

  # =============== 3. УДАЛЁННЫЕ СЕРВЕРА msk-vps* ===============
  # Один job для всех удаленных серверов - это правильный подход
  - job_name: 'vps-remote'
    static_configs:
      - targets: 
        - '172.16.15.36:9100'  # msk-vps1
        - '172.16.15.37:9100'  # msk-vps2
        - '172.16.15.38:9100'  # msk-vps3
        labels:
          location: 'remote'
          env: 'production'
    scrape_timeout: 25s
    relabel_configs:
      # Добавляем метку host на основе IP адреса
      - source_labels: [__address__]
        target_label: host
        regex: '172\.16\.15\.(\d+):9100'
        replacement: 'msk-vps$1'
      - source_labels: [__address__]
        target_label: service
        replacement: 'node-exporter'
      - source_labels: [__address__]
        target_label: component
        replacement: 'infrastructure'

# Можно изменить regex для получения более красивых имен:
#relabel_configs:
#  - source_labels: [__address__]
#    target_label: host
#    regex: '172\.16\.15\.(36|37|38):9100'
#    replacement: 'msk-vps-$1'
  # или даже так:
#  - source_labels: [__address__]
#    target_label: host
#    regex: '172\.16\.15\.36:9100'
#    replacement: 'web-server-1'
#  - source_labels: [__address__]
#    target_label: host  
#    regex: '172\.16\.15\.37:9100'
#    replacement: 'db-server'
#  - source_labels: [__address__]
#    target_label: host
#    regex: '172\.16\.15\.38:9100'
#    replacement: 'app-server'

  # =============== 4. LOKI (лог-система) ===============
  # Метрики системы логирования Loki
  - job_name: 'loki'
    static_configs:
      - targets: ['localhost:3100']
        labels:
          host: 'runelfrontdev'
          service: 'loki'
          component: 'logging'
          env: 'production'
    metrics_path: '/metrics'
    scrape_interval: 30s

  # =============== 5. PROMTAIL ===============
  # Метрики сборщика логов Promtail
  - job_name: 'promtail'
    static_configs:
      - targets: ['localhost:9080']
        labels:
          host: 'runelfrontdev'
          service: 'promtail'
          component: 'logging'
          env: 'production'
    metrics_path: '/metrics'
    scrape_interval: 30s

  # =============== 6. GRAFANA ===============
  # Метрики Grafana (опционально)
  - job_name: 'grafana'
    static_configs:
      - targets: ['localhost:3000']
        labels:
          host: 'runelfrontdev'
          service: 'grafana'
          component: 'monitoring'
          env: 'production'
    metrics_path: '/metrics'
    scrape_interval: 30s
```
</details>

=-=-=-=-=-=-=-=
<details>
<summary>❗ отдельные job для каждого сервера ❗</summary>

```yaml
  # Вариант с отдельными job для каждого сервера
  - job_name: 'node-msk-vps1'
    static_configs:
      - targets: ['172.16.15.36:9100']
        labels:
          host: 'msk-vps1'
          service: 'node-exporter'
          component: 'infrastructure'
          location: 'remote'
          env: 'production'
    scrape_timeout: 25s

  - job_name: 'node-msk-vps2'
    static_configs:
      - targets: ['172.16.15.37:9100']
        labels:
          host: 'msk-vps2'
          service: 'node-exporter'
          component: 'infrastructure'
          location: 'remote'
          env: 'production'
    scrape_timeout: 25s

  - job_name: 'node-msk-vps3'
    static_configs:
      - targets: ['172.16.15.38:9100']
        labels:
          host: 'msk-vps3'
          service: 'node-exporter'
          component: 'infrastructure'
          location: 'remote'
          env: 'production'
    scrape_timeout: 25s
```
</details>

### Объяснение регулярки:
1. `source_labels: [__address__]` - берем исходный адрес target (например 172.16.15.36:9100)
2. `regex: '172\.16\.15\.(\d+):9100'` - применяем регулярное выражение
3. `172\.16\.15\.` - ищем этот паттерн
4. `(\d+)` - захватываем последний октет IP (36, 37, 38)
5. `replacement: 'msk-vps$1'` - заменяем на `msk-vps` + захваченное число
6. `target_label: host` - сохраняем результат в метку host

Результат для каждого сервера:
- 172.16.15.36:9100 → host="msk-vps36"
- 172.16.15.37:9100 → host="msk-vps37"
- 172.16.15.38:9100 → host="msk-vps38"

### Как использовать в запросах PromQL:
```promql
# Все метрики CPU для всех VPS
node_cpu_seconds_total{job="node-vps"}

# Только для конкретного хоста
node_cpu_seconds_total{host="msk-vps36"}

# Группировка по хосту
sum(rate(node_cpu_seconds_total{job="node-vps", mode="idle"}[5m])) by (host)
```


Проверка синтаксиса:
```bash
promtool check config /etc/prometheus/prometheus.yml
```
<br/>


## Шаг 4: Проверка доступности удалённого node-exporter

### Проверьте подключение:
```bash
curl -s --max-time 5 http://192.168.195.122:9100/metrics | head -5
```

### Если недоступен - настройте firewall на starodubtcevs:
```bash
ssh root@starodubtcevs.hlab.kz "
# Проверьте текущие правила
sudo ufw status
sudo iptables -L -n | grep 9100

# Откройте порт (выберите один вариант)
sudo ufw allow 9100/tcp comment 'Prometheus node-exporter'
# Или
sudo iptables -I INPUT -p tcp --dport 9100 -j ACCEPT
"
```
<br/>


## Шаг 5: Перезапуск и проверка Prometheus

### Перезапустите службу:
```bash
sudo systemctl restart prometheus
```

### Проверьте статус:
```bash
sudo systemctl status prometheus --no-pager
sudo journalctl -u prometheus -n 20 --no-pager
```
<br/>


## Шаг 6: Проверка основных метрик Node Exporter
Зайти по ссылке http://192.168.87.209:9090/classic/graph в Graph
```promql
# Загрузка CPU
100 - (avg by (host) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# Использование памяти
node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes

# Использование диска
node_filesystem_size_bytes - node_filesystem_free_bytes

# Количество обновлений (видно из curl)
apt_upgrades_pending
```
<br/>


## Шаг 7: Проверка targets в Prometheus

### Проверка через веб-интерфейс:
- Веб-интерфейс Prometheus (http://192.168.87.179:9090)
- Prometheus Targets: http://192.168.87.179:9100/targets
- Prometheus Targets: http://192.168.87.179:9090/classic/targets
- Веб-интерфей Grafana (http://192.168.87.179:3000)


### Проверьте все цели:
```bash
curl -s http://localhost:9090/api/v1/targets | python3 -m json.tool | grep -A2 -B2 '"health"'

curl -s http://localhost:9090/api/v1/targets | jq '.data.activeTargets[].labels'
```

### Проверка конкретных метрик:
```bash
# Проверка доступности node-exporters
curl -s "http://localhost:9100/metrics" | grep -E "^node_cpu_seconds_total{mode=\"idle\"}" | head -1
curl -s --max-time 5 "http://192.168.195.122:9100/metrics" | grep -E "^node_cpu_seconds_total{mode=\"idle\"}" | head -1

# Проверка метрик Prometheus о себе
curl -s "http://localhost:9090/api/v1/query?query=prometheus_build_info" | python3 -m json.tool | grep -A2 '"metric"'
```

### Или используйте читаемый формат:

<details>
<summary>❗ читаемый формат - скрипты ❗</summary>

```bash
curl -s "http://localhost:9090/api/v1/targets" | python3 -c "
import json, sys
data = json.load(sys.stdin)
print('=== PROMETHEUS TARGETS STATUS ===')
print('Всего целей:', len(data['data']['activeTargets']))
print()
for target in data['data']['activeTargets']:
    health = target['health']
    job = target['labels'].get('job', 'unknown')
    instance = target['scrapeUrl'].replace('http://', '').replace('https://', '')
    
    if health == 'up':
        status = '✅'
    else:
        status = '❌'
    
    print(f'{status} {job:20} {instance:40} - {health}')
    # Покажем последнюю ошибку если есть
    if 'lastError' in target and target['lastError']:
        print(f'    Ошибка: {target[\"lastError\"]}')
"
```

```bash
curl -s http://localhost:9090/api/v1/targets | python3 -c "
import json, sys
data = json.load(sys.stdin)
print('=== PROMETHEUS TARGETS ===')
for target in data['data']['activeTargets']:
    status = '✅' if target['health'] == 'up' else '❌'
    print(f'{status} {target[\"scrapeUrl\"]} - {target[\"health\"]}')
"
```
</details>
<br/>


## Шаг 8: Добавление Prometheus в Grafana

### Проверьте работу Grafana:
```bash
curl -s http://localhost:3000 | head -3
```

### Инструкция по добавлению в UI:
1. Откройте браузер: http://192.168.87.179:3000
2. Логин: `admin/admin` (или ваш пароль)
3. Перейдите: **Connections** → **Data Sources**
4. Нажмите: **Add data source**
5. Выберите: **Prometheus**
6. Настройте:
   - **Name:** `Prometheus`
   - **URL:** `http://localhost:9090`
7. Нажмите: **Save & Test** (должно быть "Data source is working")

### Инструкция по добавлению Через API:
```bash
# Установите переменные (замените пароль!)
GRAFANA_URL="http://localhost:3000"
GRAFANA_USER="admin"
GRAFANA_PASS="ваш_пароль"  # Замените на ваш пароль!

# Получите API key или используйте basic auth
curl -s -X POST -H "Content-Type: application/json" \
  -d '{
    "name": "Prometheus",
    "type": "prometheus",
    "url": "http://localhost:9090",
    "access": "proxy",
    "basicAuth": false,
    "isDefault": false
  }' \
  "${GRAFANA_URL}/api/datasources" \
  --user "${GRAFANA_USER}:${GRAFANA_PASS}" | python3 -m json.tool
```
<br/>



## Шаг 9: Импорт готовых дашбордов

### Вариант A - Импорт через UI:
1. В Grafana: **Dashboards** → **New** → **Import**
2. Введите ID дашборда:
   - `1860` - Node Exporter Full
   - `11074` - 1 Node Exporter for Prometheus
   - `3662` - Prometheus 2.0 Stats
   - `6417` - Grafana Loki Dashboard
3. Выберите Prometheus как источник данных
4. Нажмите **Import**

### Вариант B - Создание простых панелей:
- CPU использование: `100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)`
- Память: `node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes`
- Диск: `node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"} * 100`
<br/>



## Шаг 10: Комплексная проверка системы

### Создайте тестовый скрипт:
```bash
cat << 'EOF' > /tmp/test_prometheus.sh
#!/bin/bash
echo "=== КОМПЛЕКСНАЯ ПРОВЕРКА PROMETHEUS ==="
echo ""

echo "1. Prometheus API:"
curl -s -o /dev/null -w "HTTP: %{http_code}\n" http://localhost:9090

echo ""
echo "2. Локальный node-exporter:"
curl -s -o /dev/null -w "HTTP: %{http_code}\n" http://localhost:9100/metrics

echo ""
echo "3. Удалённый node-exporter:"
curl -s -o /dev/null -w "HTTP: %{http_code}\n" --max-time 5 http://192.168.195.122:9100/metrics

echo ""
echo "4. Состояние всех targets:"
curl -s http://localhost:9090/api/v1/targets 2>/dev/null | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    targets = data['data']['activeTargets']
    up = sum(1 for t in targets if t['health'] == 'up')
    print(f'Активных: {up}/{len(targets)}')
    for t in targets:
        status = '✅' if t['health'] == 'up' else '❌'
        print(f'  {status} {t[\"scrapeUrl\"]}')
except:
    print('Ошибка получения targets')
"

echo ""
echo "5. Доступные метрики (первые 5):"
curl -s http://localhost:9090/api/v1/label/__name__/values 2>/dev/null | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    print(f'Всего метрик: {len(data[\"data\"])}')
    for metric in data['data'][:5]:
        print(f'  - {metric}')
except:
    print('Ошибка получения метрик')
"
EOF

chmod +x /tmp/test_prometheus.sh
/tmp/test_prometheus.sh
```
<br/>


## Полезные команды для управления:

### Проверка конфигурации:
```bash
promtool check config /etc/prometheus/prometheus.yml
```

### Просмотр метрик в реальном времени:
```bash
curl -s http://localhost:9090/api/v1/query?query=up | python3 -m json.tool
```

### Проверка конкретных метрик:
```bash
curl -s "http://localhost:9090/api/v1/query?query=node_cpu_seconds_total" | python3 -m json.tool
```

### Веб-интерфейс Prometheus:
```bash
echo "Откройте в браузере: http://192.168.87.179:9090"
```
<br/>


## Шаг 11: Установка Grafana Tempo
Что такое Grafana Tempo?
<br/> **Grafana Tempo** — это система распределенной трассировки (distributed tracing), которая хранит и визуализирует трассировки выполнения запросов в распределенных системах.

Простыми словами:
<br/> Если **Prometheus** отвечает на вопрос "Что сломалось?" **(метрики)**,
<br/> а **Loki** — "Что происходило?" **(логи)**,
<br/> то **Tempo** отвечает на вопрос "Почему это сломалось и как именно?" **(трассировки выполнения)**.

### Качаем с GitHub для Debian дистрибутива
```bash
curl -LO https://github.com/grafana/tempo/releases/download/v2.9.0/tempo_2.9.0_linux_amd64.deb
dpkg -i tempo_2.9.0_linux_amd64.deb
```
```bash
# или
curl -LO https://github.com/grafana/tempo/releases/download/v2.9.0/tempo_2.9.0_linux_amd64.tar.gz

# Распакуйте
tar xzf tempo_2.9.0_linux_amd64.tar.gz

# Установите
sudo mv tempo /usr/local/bin/
sudo mkdir -p /etc/tempo /var/lib/tempo
```
### Проверка
```bash
systemctl status tempo.service -l --no-pager

/usr/bin/tempo --version
tempo, version 2.9.0 (branch: HEAD, revision: 607c7fb69)
  build user:       
  build date:       
  go version:       go1.25.1
  platform:         linux/amd64
  tags:             unknown
```
<br/>


## Шаг 12: Конфигурирование Grafana Tempo
Ссылки с подсказками:
- [Configure Tempo](https://github.com/grafana/tempo/blob/main/docs/sources/tempo/configuration/_index.md)
- [grafana.com/docs/tempo/](https://grafana.com/docs/tempo/latest/configuration/)

1. Создать конфигурацию.
Создать файл `/etc/tempo/tempo.yaml`

<details>
<summary>❗ tempo.yaml ❗</summary>

конфиг для версии tempo 2.9.0

```yaml
# /etc/tempo/tempo.yaml

# ==================== ОБЩИЕ НАСТРОЙКИ ====================
stream_over_http_enabled: true
# Включает потоковую передачу трассировок через HTTP (улучшает производительность)

server:
  http_listen_port: 3200          # Основной порт для API, веб-интерфейса и метрик
  grpc_listen_port: 9095          # Внутренний gRPC порт для связи между компонентами
  log_level: info                 # Уровень детализации логов (debug, info, warn, error)
  # log_format: json               # Формат логов (logfmt, json)
  # http_server_read_timeout: 30s
  # http_server_write_timeout: 30s

# ==================== QUERY FRONTEND ====================
# Компонент для обработки запросов пользователей
query_frontend:
  search:
    duration_slo: 5s                     # Service Level Objective для времени поиска
    throughput_bytes_slo: 1.073741824e+09 # SLO для пропускной способности (1 GB)
    metadata_slo:
        duration_slo: 5s
        throughput_bytes_slo: 1.073741824e+09
  trace_by_id:
    duration_slo: 5s                     # SLO для поиска по ID трассировки
  
  # Дополнительные настройки:
  # max_outstanding_per_tenant: 100     # Макс. одновременных запросов на tenant
  # querier_forget_delay: 0s            # Задержка перед забыванием querier

# ==================== DISTRIBUTOR ====================
# Приемник трассировок от клиентов
distributor:
  receivers:
    otlp:                               # OpenTelemetry Protocol (современный стандарт)
      protocols:
        grpc:
          endpoint: "0.0.0.0:4317"      # gRPC OTLP приемник
        http:
          endpoint: "0.0.0.0:4318"      # HTTP OTLP приемник
    
    jaeger:                             # Совместимость с Jaeger
      protocols:
        grpc:
          endpoint: "0.0.0.0:14250"     # Jaeger gRPC порт
        thrift_http:
          endpoint: "0.0.0.0:14268"     # Jaeger Thrift over HTTP
    
    zipkin:                             # Совместимость с Zipkin
      endpoint: "0.0.0.0:9411"          # Zipkin порт
    
    # Дополнительные протоколы (опционально):
    # opencensus:                       # OpenCensus (устаревший)
    #   endpoint: "0.0.0.0:55678"
    #
    # kafka:                            # Прием из Apache Kafka
    #   topics: ["tempo-spans"]
    #   encoding: protobuf
    #   brokers: ["kafka:9092"]
  
  # Ограничения (раскомментировать при необходимости):
  # ingestion_rate_limit_bytes: 15000000  # 15 MB/с на tenant
  # ingestion_burst_size_bytes: 20000000  # 20 MB burst

# ==================== METRICS GENERATOR ====================
# Генерация метрик из трассировок для Prometheus
metrics_generator:
  registry:
    external_labels:                     # Метки для всех генерируемых метрик
      source: tempo                      # Источник метрик
      cluster: local                     # Идентификатор кластера
      # env: production                  # Окружение (добавить при необходимости)
      # region: eu-west                  # Регион
  
  storage:
    path: /var/lib/tempo/generator/wal  # Write-Ahead Log для метрик
    remote_write:                       # Отправка метрик в Prometheus
      - url: http://localhost:9090/api/v1/write  # Ваш Prometheus
        send_exemplars: true            # Включить exemplars (связь метрик с трассировками)
        # basic_auth:                    # Аутентификация (если нужна)
        #   username: prometheus
        #   password: ${PROMETHEUS_PASSWORD}
        # write_relabel_configs:          # Переименование меток
        #   - source_labels: [__name__]
        #     regex: 'tempo_(.*)'
        #     target_label: name
        #     replacement: 'tempo_${1}'
  
  traces_storage:
    path: /var/lib/tempo/generator/traces   # Временное хранение трассировок для генерации метрик
  
  # Конфигурация процессоров (уже указана в overrides):
  # processor:
  #   service_graphs:                   # Генерация графа сервисов
  #     histogram_buckets: [0.1, 0.2, 0.4, 0.8, 1.6, 3.2]
  #     dimensions: ["client", "server", "http.status_code"]
  #   span_metrics:                     # Метрики из spans
  #     histogram_buckets: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1]
  #     dimensions: ["service", "span_name", "span_kind", "status_code"]
  #   local_blocks:                     # Локальные блоки

# ==================== STORAGE ====================
# Хранилище трассировок
storage:
  trace:
    backend: local                      # Локальная файловая система
    wal:                                # Write-Ahead Log (обеспечивает надежность)
      path: /var/lib/tempo/wal
      # encoding: snappy                # Устарело в версии 2.9.0
    local:                              # Основное хранилище
      path: /var/lib/tempo/blocks
      # block_concurrency: 10           # Количество concurrent операций с блоками
    
    # Пул воркеров (опционально):
    # pool:
    #   max_workers: 100                # Макс. воркеров для записи (по умолчанию 400)
    #   queue_depth: 10000              # Глубина очереди (по умолчанию 20000)
    
    # Альтернативные бэкенды (для продакшена):
    # backend: s3                       # Amazon S3 или S3-совместимое хранилище
    # s3:
    #   bucket: "tempo-traces"
    #   endpoint: "s3.amazonaws.com"
    #   region: "us-east-1"
    #   access_key: "${AWS_ACCESS_KEY_ID}"
    #   secret_key: "${AWS_SECRET_ACCESS_KEY}"
    #   insecure: false
    
    # backend: gcs                      # Google Cloud Storage
    # gcs:
    #   bucket_name: "tempo-traces"
    #   chunk_buffer_size: 10485760
    
    # backend: azure                    # Azure Blob Storage
    # azure:
    #   storage_account_name: "account"
    #   storage_account_key: "${AZURE_KEY}"
    #   container_name: "tempo"

# ==================== OVERRIDES ====================
# Переопределения настроек (по умолчанию и по tenant'ам)
overrides:
  defaults:
    metrics_generator:
      processors: [service-graphs, span-metrics, local-blocks]  # Включенные процессоры
    
    # Дополнительные переопределения (раскомментировать при необходимости):
    # ingestion_rate_limit_mb: 15       # Лимит приема в MB/сек (альтернатива bytes)
    # ingestion_burst_size_mb: 20       # Burst в MB
    # max_traces_per_user: 10000        # Макс. трассировок на пользователя
    # max_bytes_per_trace: 5000000      # 5MB на трассировку
    # max_search_duration: 30m          # Макс. длительность поиска
    # metrics_generator_processors: [service-graphs, span-metrics]  # Альтернативный синтаксис
  
  # Переопределения для конкретных tenant'ов:
  # per_tenant_override_config: /etc/tempo/overrides.yaml

# ==================== ДОПОЛНИТЕЛЬНЫЕ СЕКЦИИ (ОПЦИОНАЛЬНО) ====================

# обработка трассировок (дополнительные настройки):
ingester:
  # max_block_duration: 5m             # Макс. время жизни блока в памяти
  # trace_idle_period: 30s             # Время бездействия перед записью
  # max_block_bytes: 100_000_000       # 100MB макс. размер блока
  # lifecycler:
  #   ring:
  #     kvstore:
  #       store: memberlist            # Для кластера
  #     replication_factor: 3          # Фактор репликации
  #     heartbeat_timeout: 1m

# сжатие и удаление данных:
compactor:
  # compaction:
  #   compaction_window: 1h            # Окно компрессии
  #   max_block_bytes: 1_000_000_000   # 1GB макс. размер после сжатия
  #   block_retention: 168h            # 7 дней хранения
  #   vertical_compaction_strategies:
  #     - size: 512MB
  #       stages: 2
  #     - size: 1GB
  #       stages: 2

# Кластеризация (для распределенного режима):
# memberlist:
#   join_members: ["tempo-1:7946", "tempo-2:7946", "tempo-3:7946"]
#   bind_port: 7946
#   gossip_to_dead_nodes_time: 30s
#   gossip_interval: 5s
#   retransmit_mult: 3

# Трассировка самого Tempo (отладка):
# tracing:
#   enabled: true
#   sampling_fraction: 0.01            # Отправлять 1% трассировок самого Tempo
#   jaeger:
#     collector:
#       endpoint: "localhost:14250"    # Куда отправлять (можно в самого себя)
#   # или OTLP:
#   # otlp:
#   #   endpoint: "localhost:4317"

# Безопасность (TLS):
# tls:
#   enabled: true
#   cert_file: "/etc/tempo/certs/tls.crt"
#   key_file: "/etc/tempo/certs/tls.key"
#   client_auth_type: "RequireAndVerifyClientCert"
#   client_ca_file: "/etc/tempo/certs/ca.crt"

# Аутентификация:
# authentication:
#   enabled: true
#   type: "basic"  # или "bearer", "mtls"
#   basic:
#     username: "tempo"
#     password: "${TEMPO_PASSWORD}"

# ==================== ПРОВЕРКА РАБОТОСПОСОБНОСТИ ====================
# Команды для проверки:
# curl http://localhost:3200/ready      # Проверка готовности
# curl http://localhost:3200/status     # Статус и версия
# curl http://localhost:3200/metrics    # Метрики Prometheus
# curl http://localhost:3200/api/search/tags  # Доступные теги для поиска

# ==================== ИНТЕГРАЦИЯ ====================
# Prometheus: Добавить job в prometheus.yml:
# - job_name: 'tempo'
#   static_configs:
#     - targets: ['localhost:3200']
#   metrics_path: '/metrics'
#
# Grafana: Добавить Data Source типа Tempo:
# URL: http://localhost:3200
# Порт: 3200
```
</details>

### Секция **`server`** - настройки сервера
Важные порты:
- `4317` - gRPC OTLP (основной для новых приложений)
- `4318` - HTTP OTLP
- `14250` - Jaeger gRPC
- `9411` - Zipkin

### Секция **`distributor`** - прием трассировок
- `OTLP (OpenTelemetry Protocol)` - современный стандарт
- `Jaeger` - совместимость с Jaeger клиентами
- `Zipkin` - совместимость с Zipkin
- `Kafka` - для масштабирования, если трассировок очень много

### Секция **`ingester`** - обработка трассировок
- `Блок` - группа трассировок в памяти перед записью на диск
- `5m` - если блок живет дольше 5 минут - записываем на диск
- `10s` - если трассировка не получает новых spans 10 секунд - считаем её завершенной
- `100MB` - если блок больше 100MB - записываем на диск

### Секция **`compactor`** - сжатие и удаление
- `Retention (удержание)` - сколько хранить трассировки
- `24h` - хранить сырые трассировки 24 часа (можно увеличить до 7 дней)
- `Компрессия` уменьшает место на диске в 5-10 раз
- `Compaction window` - как часто запускать сжатие

### Секция **`storage`** - хранилище трассировок
Использование нескольких бэкендов
```ini
storage:
  trace:
    backend: s3
    s3:
      bucket: tempo-traces-hot        # Горячие данные (последние 7 дней)
      endpoint: s3.amazonaws.com
      access_key: "..."
      secret_key: "..."
    
    # Многоуровневое хранилище
    # trace_id_index:
    #   backend: s3
    #   s3:
    #     bucket: tempo-index         # Индекс отдельно
    # 
    # block_index:
    #   backend: s3
    #   s3:
    #     bucket: tempo-block-index   # Индекс блоков
```

### Секция **`search_enabled`** и **search`** - поиск трассировок

### Секция **`metrics_generator`** - генерация метрик из трассировок
Что генерируется:
- `tempo_metrics_generator_spans_processed_total` - сколько spans обработано
- `tempo_request_duration_seconds` - гистограмма длительностей запросов
- `tempo_service_graph_request_total` - граф зависимостей сервисов


2. Создать\обновить systemd юнит
```bash
mcedit /etc/systemd/system/tempo.service
```
```ini
[Unit]
Description=Grafana Tempo - Distributed Tracing Backend
Documentation=https://grafana.com/docs/tempo/latest/
After=network.target prometheus.service loki.service

[Service]
Type=simple
User=root
Group=root
#ExecStart=/usr/local/bin/tempo -config.file=/etc/tempo/tempo.yaml
ExecStart=/usr/bin/tempo -config.file /etc/tempo/config.yml
Restart=always
RestartSec=5
StandardOutput=journal
StandardError=journal
SyslogIdentifier=tempo
LimitNOFILE=65536
LimitNPROC=65536

# Security
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/var/lib/tempo /etc/tempo

[Install]
WantedBy=multi-user.target
```


3. Проверить конфигурацию
```bash
/usr/bin/tempo --config.file=/etc/tempo/tempo.yaml --check-config
```
после добавления секции\джобы с TEMPO в /etc/prometheus/prometheus.yml, проверьте конфиг (отступы)
```bash
promtool check config /etc/prometheus/prometheus.yml
```


4. Проверить доступность
- curl http://192.168.87.179:3200/status
- curl http://192.168.87.179:3200/ready
- curl http://192.168.87.179:3200/metrics

Проверить метрики (пярмой запрос)
```bash
curl -s "http://localhost:9090/api/v1/series?match[]=%7Bjob%3D%22tempo%22%7D" | python3 -m json.tool
```
```bash
echo "=== МЕТРИКИ НАПРЯМУЮ ОТ TEMPO (прямой запрос) ==="
curl -s http://localhost:3200/metrics | grep -E "^tempo_" | head -10
if [ $? -eq 0 ]; then
    echo "✅ Tempo отдает свои метрики"
else
    echo "❌ Tempo не отдает tempo_* метрики"
    echo "Проверяем все метрики:"
    curl -s http://localhost:3200/metrics | grep -E "^[^#]" | head -20
fi
```

```bash

```

<details>
<summary>❗ скрипт проверки TEMPO ❗</summary>

```bash
# 1. Все метрики от Tempo
curl -s "http://localhost:9090/api/v1/series?match[]={job=\"tempo\"}" | python3 -c "
import json, sys
data = json.load(sys.stdin)
series = data.get('data', [])
print(f'1. Метрики с job=\"tempo\": {len(series)}')
if series:
    tempo_metrics = [s for s in series if s.get('__name__', '').startswith('tempo_')]
    print(f'   Из них tempo_*: {len(tempo_metrics)}')
    for s in tempo_metrics[:5]:
        print(f'   - {s.get(\"__name__\")}')
"

# 2. Прямой запрос к конкретной метрике
echo ""
echo "2. Прямой запрос к tempo_build_info:"
curl -s "http://localhost:9090/api/v1/query?query=tempo_build_info" | python3 -c "
import json, sys
data = json.load(sys.stdin)
results = data.get('data', {}).get('result', [])
print(f'   Найдено результатов: {len(results)}')
for r in results:
    metric = r['metric']
    if 'tempo' in str(metric.get('job', '')):
        print(f'   ✅ Tempo метрика найдена!')
        print(f'      Version: {metric.get(\"version\", \"unknown\")}')
        print(f'      Метки: {metric}')
"

# 3. Проверка всех метрик
echo ""
echo "3. Все метрики Tempo в Prometheus:"
curl -s "http://localhost:9090/api/v1/series?match[]={instance=~\"localhost.*\"}" | python3 -c "
import json, sys
data = json.load(sys.stdin)
series = data.get('data', [])
# Фильтруем tempo метрики
tempo_series = [s for s in series if s.get('__name__', '').startswith('tempo_')]
print(f'   Всего tempo_* метрик: {len(tempo_series)}')
if tempo_series:
    print('   Примеры:')
    for s in tempo_series[:10]:
        print(f'   - {s.get(\"__name__\")}')
"

# 4. Базовые GO метрики
echo "=== БАЗОВЫЕ МЕТРИКИ GO (должны быть всегда) ==="
curl -s http://localhost:3200/metrics | grep -E "^(go_|process_)" | wc -l
echo "Базовых метрик Go: $?"

# Если есть базовые метрики, значит Tempo отдает метрики
# И проблема в том, что Prometheus не собирает их
```
</details>


## Шаг 13: Добавление в UI
1. Откройте браузер: http://192.168.87.179:3000
2. Логин: `admin/admin` (или ваш пароль)
3. Перейдите: **Connections** → **Data Sources**
4. Нажмите: **Add data source**
5. Выберите: **Tempo**
6. Настройте:
   - **Name:** `Tempo`
   - **URL:** `[http://localhost:9090](http://localhost:3200)`
7. Нажмите: **Save & Test** (должно быть "Data source is working")
<br/>


## Шаг 14: Установка Pyroscope
### Качаем любым удобным способом
```
wget -q  или  curl -LO

https://github.com/grafana/pyroscope/releases/download/v1.17.0/pyroscope_1.17.0_linux_amd64.tar.gz
https://github.com/grafana/pyroscope/releases/download/v1.17.0/profilecli_1.17.0_linux_amd64.tar.gz
```
### Распаковываем и копируем содержимое в `/usr/local/bin/`
```bash
tar xzf pyroscope_1.17.0_linux_amd64.tar.gz
tar xzf profilecli_1.17.0_linux_amd64.tar.gz

# Проверим что внутри архива (бинарник)
file /usr/local/bin/pyroscope
file /usr/local/bin/profilecli

# Поищем бинарники
find . -name "pyroscope" -type f -executable 2>/dev/null | head -5
find . -name "profilecli" -type f -executable 2>/dev/null | head -5

mv pyroscope /usr/local/bin/
mv profilecli /usr/local/bin/

chown root:root /usr/local/bin/pyroscope /usr/local/bin/profilecli
chmod 755 /usr/local/bin/pyroscope /usr/local/bin/profilecli

ls -alF /usr/local/bin/ | grep -E "(pyroscope|profilecli)"
```

### Создаём systemd юнит
```ini

```








